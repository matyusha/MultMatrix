{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyNtryK0gBzmTG8zUajVOTp6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matyusha/MultMatrix/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFvnKjEiQMMx",
        "outputId": "e0d4adb9-6eae-4de3-952c-2c49b491f57a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.6/dist-packages (2020.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.6/dist-packages (from pycuda) (2020.4.3)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.1.3)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7; python_version <= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRBv6apXRv7P",
        "outputId": "e8ba9d97-ee73-45c7-ecd5-c627b33aa691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pycuda.autoinit\n",
        "from pycuda.tools import make_default_context\n",
        "make_default_context().get_device().name()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbJfNcRXSisv",
        "outputId": "ea8884f3-e58b-452f-bbce-0a1ad0c5aa22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\"\n",
        "Multiples two square matrices together using multiple blocks and shared memory.\n",
        "Each thread block is assigned a \"tile\" of the resulting matrix and is responsible\n",
        "for generating the elements in that tile.  Each thread in a block computes one element\n",
        "of the tile.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "from time import time\n",
        "\n",
        "for i in range(0, 5):\n",
        "  # define the (square) matrix size\n",
        "  MATRIX_SIZE = 128*2**i\n",
        "  print(\"MATRIX_SIZE\", MATRIX_SIZE)\n",
        "\n",
        "  def matmul(a_gpu,b_gpu,MATRIX_SIZE=MATRIX_SIZE):\n",
        "    kernel_code_template = \"\"\"\n",
        "    __global__ void MatrixMulKernel(float *A, float *B, float *C)\n",
        "    {\n",
        "\n",
        "      const uint wA = %(MATRIX_SIZE)s;\n",
        "      const uint wB = %(MATRIX_SIZE)s;\n",
        "\n",
        "      // Block index\n",
        "      const uint bx = blockIdx.x;\n",
        "      const uint by = blockIdx.y;\n",
        "\n",
        "      // Thread index\n",
        "      const uint tx = threadIdx.x;\n",
        "      const uint ty = threadIdx.y;\n",
        "\n",
        "      // Index of the first sub-matrix of A processed by the block\n",
        "      const uint aBegin = wA * %(BLOCK_SIZE)s * by;\n",
        "      // Index of the last sub-matrix of A processed by the block\n",
        "      const uint aEnd = aBegin + wA - 1;\n",
        "      // Step size used to iterate through the sub-matrices of A\n",
        "      const uint aStep = %(BLOCK_SIZE)s;\n",
        "\n",
        "      // Index of the first sub-matrix of B processed by the block\n",
        "      const uint bBegin = %(BLOCK_SIZE)s * bx;\n",
        "      // Step size used to iterate through the sub-matrices of B\n",
        "      const uint bStep = %(BLOCK_SIZE)s * wB;\n",
        "\n",
        "      // The element of the block sub-matrix that is computed\n",
        "      // by the thread\n",
        "      float Csub = 0;\n",
        "      // Loop over all the sub-matrices of A and B required to\n",
        "      // compute the block sub-matrix\n",
        "      for (int a = aBegin, b = bBegin;\n",
        "           a <= aEnd;\n",
        "           a += aStep, b += bStep)\n",
        "        {\n",
        "          // Shared memory for the sub-matrix of A\n",
        "          __shared__ float As[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "          // Shared memory for the sub-matrix of B\n",
        "          __shared__ float Bs[%(BLOCK_SIZE)s][%(BLOCK_SIZE)s];\n",
        "\n",
        "          // Load the matrices from global memory to shared memory\n",
        "          // each thread loads one element of each matrix\n",
        "          As[ty][tx] = A[a + wA * ty + tx];\n",
        "          Bs[ty][tx] = B[b + wB * ty + tx];\n",
        "          // Synchronize to make sure the matrices are loaded\n",
        "          __syncthreads();\n",
        "\n",
        "          // Multiply the two matrices together;\n",
        "          // each thread computes one element\n",
        "          // of the block sub-matrix\n",
        "          for (int k = 0; k < %(BLOCK_SIZE)s; ++k)\n",
        "            Csub += As[ty][k] * Bs[k][tx];\n",
        "\n",
        "          // Synchronize to make sure that the preceding\n",
        "          // computation is done before loading two new\n",
        "          // sub-matrices of A and B in the next iteration\n",
        "          __syncthreads();\n",
        "        }\n",
        "\n",
        "      // Write the block sub-matrix to global memory;\n",
        "      // each thread writes one element\n",
        "      const uint c = wB * %(BLOCK_SIZE)s * by + %(BLOCK_SIZE)s * bx;\n",
        "      C[c + wB * ty + tx] = Csub;\n",
        "\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # define size of blocks and tiles sub-matrix\n",
        "    # (we assume that the block size is same as tile size)\n",
        "    TILE_SIZE = 32\n",
        "    BLOCK_SIZE = TILE_SIZE\n",
        "\n",
        "    # get the kernel code from the template\n",
        "    # by specifying the constants MATRIX_SIZE and BLOCK_SIZE\n",
        "    kernel_code = kernel_code_template % {\n",
        "        'MATRIX_SIZE': MATRIX_SIZE,\n",
        "        'BLOCK_SIZE': BLOCK_SIZE,\n",
        "        }\n",
        "\n",
        "    # compile the kernel code\n",
        "    mod = compiler.SourceModule(kernel_code)\n",
        "    # create empty gpu array for the result (C = A * B)\n",
        "    c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "    # get the kernel function from the compiled module\n",
        "    matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "    # call the kernel on the card\n",
        "    matrixmul(\n",
        "        # inputs\n",
        "        a_gpu, b_gpu,\n",
        "        # output\n",
        "        c_gpu,\n",
        "        # grid of multiple blocks\n",
        "        grid = (MATRIX_SIZE // TILE_SIZE, MATRIX_SIZE // TILE_SIZE),\n",
        "        # block of multiple threads\n",
        "        block = (TILE_SIZE, TILE_SIZE, 1),\n",
        "        )\n",
        "\n",
        "    return c_gpu\n",
        "\n",
        "  # create two random square matrices\n",
        "  a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "  b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "\n",
        "  st = time()\n",
        "  # compute reference on the CPU to verify GPU computation\n",
        "  c_cpu = np.dot(a_cpu, b_cpu)\n",
        "  cpu_time = time() - st\n",
        "\n",
        "  st = time()\n",
        "  # transfer host (CPU) memory to device (GPU) memory\n",
        "  a_gpu = gpuarray.to_gpu(a_cpu)\n",
        "  b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "  c_gpu = matmul(a_gpu,b_gpu).get()\n",
        "  gpu_time = time() - st\n",
        "\n",
        "  print(\"TIME ON CPU: {:.6f}\".format(cpu_time))\n",
        "  print(\"TIME ON GPU: {:.6f}\".format(gpu_time))\n",
        "  print(\"SPEEDUP {:.3f}\".format(cpu_time/gpu_time)) \n",
        "  print(\"CPU-GPU difference: {:.6f}\".format(np.max(c_cpu - c_gpu)))\n",
        "  print()\n",
        "  print(\"-\" * 80)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MATRIX_SIZE 128\n",
            "TIME ON CPU: 0.000363\n",
            "TIME ON GPU: 0.003791\n",
            "SPEEDUP 0.096\n",
            "CPU-GPU difference: 0.000000\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "MATRIX_SIZE 256\n",
            "TIME ON CPU: 0.000772\n",
            "TIME ON GPU: 0.002470\n",
            "SPEEDUP 0.312\n",
            "CPU-GPU difference: 0.000000\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "MATRIX_SIZE 512\n",
            "TIME ON CPU: 0.004060\n",
            "TIME ON GPU: 0.003418\n",
            "SPEEDUP 1.188\n",
            "CPU-GPU difference: 0.000076\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "MATRIX_SIZE 1024\n",
            "TIME ON CPU: 0.036452\n",
            "TIME ON GPU: 0.011924\n",
            "SPEEDUP 3.057\n",
            "CPU-GPU difference: 0.000183\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "MATRIX_SIZE 2048\n",
            "TIME ON CPU: 0.269966\n",
            "TIME ON GPU: 0.057906\n",
            "SPEEDUP 4.662\n",
            "CPU-GPU difference: 0.000427\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}